{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(input_shape, output_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(50, activation='relu', return_sequences=True, input_shape=input_shape),\n",
    "        LSTM(50, activation='relu'),\n",
    "        Dense(output_shape)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data_glucose(num_individuals=12, num_samples=1000, timesteps=24):\n",
    "    X_data, y_data, individuals = [], [], []\n",
    "    for i in range(num_individuals):\n",
    "        base_value = np.random.uniform(80, 180)  # Define um ponto de partida realista\n",
    "        noise = np.cumsum(np.random.normal(0, 5, size=(num_samples, timesteps,1)))  # Suaviza variações\n",
    "        # X = np.clip(base_value + noise, 40, 300)  # Mantém os valores no intervalo desejado\n",
    "        X = np.clip(base_value + np.random.normal(0, 5, size=(num_samples,timesteps, 1)), 40, 300)\n",
    "        y = np.clip(base_value + np.random.normal(0, 5, size=(num_samples, 6)), 40, 300)  # Glicose futura\n",
    "        X_data.append(X)\n",
    "        y_data.append(y)\n",
    "        individuals.extend([i] * num_samples)\n",
    "    return np.vstack(X_data), np.vstack(y_data), np.array(individuals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(num_individuals=12, num_samples=1000, timesteps=10):\n",
    "    X_data, y_data, individuals = [], [], []\n",
    "    for i in range(num_individuals):\n",
    "        X = np.random.rand(num_samples, timesteps, 1)  # Sequências de glicose simuladas\n",
    "        y = np.random.rand(num_samples, 1)  # Valores de glicose futura\n",
    "        X_data.append(X)\n",
    "        y_data.append(y)\n",
    "        individuals.extend([i] * num_samples)\n",
    "    return np.vstack(X_data), np.vstack(y_data), np.array(individuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando dados sintéticos\n",
    "X, y, individuals = generate_synthetic_data()\n",
    "X_gl, y_gl, individuals_gl = generate_synthetic_data_glucose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n",
      "12000\n",
      "[[103.00087166]\n",
      " [ 92.88345207]\n",
      " [100.16792323]\n",
      " [ 96.925653  ]\n",
      " [103.36958161]\n",
      " [ 94.76669535]\n",
      " [100.94423116]\n",
      " [102.62102675]\n",
      " [106.13334347]\n",
      " [102.9148513 ]\n",
      " [102.82444095]\n",
      " [104.22290653]\n",
      " [102.37986577]\n",
      " [105.25878611]\n",
      " [102.89722011]\n",
      " [109.21936188]\n",
      " [100.93686544]\n",
      " [ 93.63719751]\n",
      " [109.5647755 ]\n",
      " [ 94.61965772]\n",
      " [108.20895251]\n",
      " [109.11798959]\n",
      " [102.68425442]\n",
      " [ 96.37743199]]\n",
      "[107.32593765 104.38048737 106.08543943  98.19261245  99.35973553\n",
      " 105.55587573]\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(X_gl))\n",
    "print(len(y_gl))\n",
    "print(X_gl[0])\n",
    "print(y_gl[0])\n",
    "print(individuals_gl[999])\n",
    "print(individuals_gl[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 24, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_gl.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n",
      "12000\n",
      "[[0.03892328]\n",
      " [0.67724476]\n",
      " [0.20924335]\n",
      " [0.77096238]\n",
      " [0.0292669 ]\n",
      " [0.75698441]\n",
      " [0.30942785]\n",
      " [0.7717496 ]\n",
      " [0.11957058]\n",
      " [0.20272422]]\n",
      "[0.89577222]\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(X))\n",
    "print(len(y))\n",
    "print(X[0])\n",
    "print(y[0])\n",
    "print(individuals[999])\n",
    "print(individuals[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_gl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 24, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_gl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 11:12:46.204986: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 4s 11ms/step - loss: 3224.7805 - val_loss: 134.5418\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 51.1808 - val_loss: 43.4130\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 36.6822 - val_loss: 36.6498\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 33.5439 - val_loss: 33.7268\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 31.8801 - val_loss: 32.1497\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 34.5579 - val_loss: 32.4881\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 37.7235 - val_loss: 85.6711\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 42.7043 - val_loss: 41.8479\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 35.2431 - val_loss: 36.1676\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 32.9799 - val_loss: 33.3824\n",
      "75/75 [==============================] - 0s 3ms/step\n",
      "Population Training RMSE: 5.7778\n"
     ]
    }
   ],
   "source": [
    "# Population Training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_gl, y_gl, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "model_pop = create_lstm_model(input_shape=(X_gl.shape[1], X_gl.shape[2]),output_shape=y_gl.shape[1])\n",
    "model_pop.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "y_pred_pop = model_pop.predict(X_test)\n",
    "rmse_pop = np.sqrt(mean_squared_error(y_test, y_pred_pop))\n",
    "print(f'Population Training RMSE: {rmse_pop:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 2s 9ms/step - loss: 25273.0527 - val_loss: 24985.3379\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 58392.2617 - val_loss: 578.6183\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 197.2065 - val_loss: 150.4345\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 124.6428 - val_loss: 125.5824\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 183.9135 - val_loss: 392.1653\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 260.6801 - val_loss: 222.5048\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 159.1070 - val_loss: 100.9145\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 76.4723 - val_loss: 62.6549\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 63.2709 - val_loss: 56.0910\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 57.8624 - val_loss: 53.5197\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "Personalized Training RMSE for individual 0: 7.3157\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 2s 9ms/step - loss: 10037.7432 - val_loss: 2256.5215\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 763.2681 - val_loss: 3433.0127\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 23328.9102 - val_loss: 13468.5576\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 10053.0410 - val_loss: 6119.5308\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 442.1722 - val_loss: 56.7866\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 55.3232 - val_loss: 50.3409\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 43.4970 - val_loss: 36.5314\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 41.1783 - val_loss: 35.9670\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 38.0146 - val_loss: 35.0979\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 37.7333 - val_loss: 35.1848\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "Personalized Training RMSE for individual 1: 5.9317\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 2s 9ms/step - loss: 17132.5391 - val_loss: 23670.4082\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 16195.4102 - val_loss: 8239.6357\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 5432.6050 - val_loss: 3060.6260\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 12852.4014 - val_loss: 6014.2773\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 4259.2095 - val_loss: 2617.6721\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1492.1807 - val_loss: 445.7498\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 792.6425 - val_loss: 115.8224\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 101.4161 - val_loss: 65.4933\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 73.4657 - val_loss: 47.6983\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 63.3009 - val_loss: 51.1982\n",
      "7/7 [==============================] - 0s 8ms/step\n",
      "Personalized Training RMSE for individual 2: 7.1553\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 2s 9ms/step - loss: 3263.7280 - val_loss: 175.4512\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 66.7763 - val_loss: 45.1079\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 40.2507 - val_loss: 44.4187\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 43.5706 - val_loss: 40.8894\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1457.0144 - val_loss: 4148.6191\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 17490.2188 - val_loss: 49.4814\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 46.9446 - val_loss: 44.4658\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 41.5692 - val_loss: 42.4314\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 37.4153 - val_loss: 40.8390\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 36.9815 - val_loss: 37.5844\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "Personalized Training RMSE for individual 3: 6.1306\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 2s 10ms/step - loss: 9392.5498 - val_loss: 3049.8682\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 3191.1628 - val_loss: 137.2255\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 102.7442 - val_loss: 69.3772\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 72.0933 - val_loss: 66.4822\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 62.1838 - val_loss: 56.9505\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 52.4858 - val_loss: 49.4969\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 47.8981 - val_loss: 45.7331\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 43.1102 - val_loss: 44.2902\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 41.7394 - val_loss: 42.3982\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 39.8642 - val_loss: 49.8127\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "Personalized Training RMSE for individual 4: 7.0578\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 2s 10ms/step - loss: 8540.9561 - val_loss: 183.0454\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 91.1704 - val_loss: 68.2068\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 52.3268 - val_loss: 51.3934\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 43.8875 - val_loss: 46.3284\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 39.1182 - val_loss: 46.1045\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 37.4410 - val_loss: 41.4112\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 35.8275 - val_loss: 40.0336\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 35.0715 - val_loss: 35.1891\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 33.7511 - val_loss: 35.6101\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 33.7460 - val_loss: 33.9407\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "Personalized Training RMSE for individual 5: 5.8259\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 2s 9ms/step - loss: 9431.9658 - val_loss: 1237.6746\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 500.4959 - val_loss: 155.0590\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 132.6782 - val_loss: 80.1637\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 65.3424 - val_loss: 60.2477\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 211.2015 - val_loss: 119.5194\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 157.4427 - val_loss: 193.6850\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 2926.0674 - val_loss: 388.8212\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 211.8296 - val_loss: 47.5636\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 44.0573 - val_loss: 36.1074\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 49.6569 - val_loss: 35.1385\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "Personalized Training RMSE for individual 6: 5.9278\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 2s 9ms/step - loss: 20486.3242 - val_loss: 2589.8665\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 401.8761 - val_loss: 67.0874\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 57.8024 - val_loss: 48.6000\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 552.5765 - val_loss: 2712.4719\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1642.1556 - val_loss: 54.6051\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 38.9480 - val_loss: 33.7558\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 34.1336 - val_loss: 31.4433\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 32.8019 - val_loss: 30.3422\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 32.4729 - val_loss: 30.0539\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 32.4395 - val_loss: 30.5072\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "Personalized Training RMSE for individual 7: 5.5233\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 2s 9ms/step - loss: 3865.9790 - val_loss: 40.8289\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 34.2709 - val_loss: 30.0079\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 30.7850 - val_loss: 29.2515\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 29.9547 - val_loss: 31.2286\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 29.4037 - val_loss: 32.0824\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 29.2861 - val_loss: 29.9004\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 29.2940 - val_loss: 28.5173\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 29.4195 - val_loss: 28.5573\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 30.1770 - val_loss: 29.1551\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 28.3997 - val_loss: 29.5311\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "Personalized Training RMSE for individual 8: 5.4343\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 2s 9ms/step - loss: 6521.7905 - val_loss: 2983.0493\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 3346.2122 - val_loss: 651.6577\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 232.6603 - val_loss: 137.3767\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 85.6515 - val_loss: 92.5099\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 56.6191 - val_loss: 53.1730\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 45.2664 - val_loss: 50.8228\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 43.7885 - val_loss: 49.8041\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 48.6937 - val_loss: 43.6005\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 41.8114 - val_loss: 39.6397\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 39.4780 - val_loss: 37.5752\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "Personalized Training RMSE for individual 9: 6.1299\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 2s 9ms/step - loss: 3570.2229 - val_loss: 304.3753\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 115.1312 - val_loss: 51.2943\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 45.3403 - val_loss: 40.1913\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 44.4293 - val_loss: 46.3922\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 42.8219 - val_loss: 37.3127\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 53.1296 - val_loss: 49.9991\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 49.2359 - val_loss: 59.4481\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 47.8598 - val_loss: 41.5700\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 138.3729 - val_loss: 340.6462\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 84.9511 - val_loss: 43.5130\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "Personalized Training RMSE for individual 10: 6.5964\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 2s 9ms/step - loss: 24793.1680 - val_loss: 12847.2314\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2918.3931 - val_loss: 39.4324\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 35.5499 - val_loss: 34.9740\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 35.6305 - val_loss: 31.6417\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 34.1137 - val_loss: 32.4079\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 31.3730 - val_loss: 29.2090\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 31.8742 - val_loss: 32.7801\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 30.4929 - val_loss: 29.2618\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 31.3983 - val_loss: 33.0314\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 30.7636 - val_loss: 28.8085\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "Personalized Training RMSE for individual 11: 5.3674\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Personalized Training\n",
    "models_personalized = {}\n",
    "for person_id in np.unique(individuals):\n",
    "    X_person = X_gl[individuals == person_id]\n",
    "    y_person = y_gl[individuals == person_id]\n",
    "    X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X_person, y_person, test_size=0.2, random_state=42,shuffle=False)\n",
    "    model = create_lstm_model(input_shape=(X_gl.shape[1], X_gl.shape[2]), output_shape=y_gl.shape[1])\n",
    "    model.fit(X_train_p, y_train_p, epochs=10, batch_size=8, validation_data=(X_test_p, y_test_p))\n",
    "    y_pred_p = model.predict(X_test_p)\n",
    "    rmse_p = np.sqrt(mean_squared_error(y_test_p, y_pred_p))\n",
    "    print(f'Personalized Training RMSE for individual {person_id}: {rmse_p:.4f}')\n",
    "    models_personalized[person_id] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 2s 9ms/step - loss: 124.0007 - val_loss: 143.5974\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 130.1860 - val_loss: 33.3975\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 34.7266 - val_loss: 33.8589\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 32.2500 - val_loss: 30.7527\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 33.0942 - val_loss: 30.6136\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "Fine-Tuning Training RMSE for individual 0: 5.5330\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 2s 10ms/step - loss: 53.9254 - val_loss: 25.9474\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 30.2471 - val_loss: 26.2777\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 29.3814 - val_loss: 31.7944\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 30.3138 - val_loss: 26.1211\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 30.6504 - val_loss: 28.2883\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "Fine-Tuning Training RMSE for individual 1: 5.3187\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 2s 9ms/step - loss: 52.9156 - val_loss: 34.4816\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 29.8165 - val_loss: 28.7212\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 30.3086 - val_loss: 31.0562\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 30.0760 - val_loss: 31.1696\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 29.3222 - val_loss: 32.6265\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "Fine-Tuning Training RMSE for individual 2: 5.7120\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 2s 9ms/step - loss: 124.1476 - val_loss: 109.6983\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 84.6693 - val_loss: 32.9504\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 29.9076 - val_loss: 31.9111\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 28.3239 - val_loss: 30.1269\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 26.9979 - val_loss: 29.5756\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "Fine-Tuning Training RMSE for individual 3: 5.4383\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 2s 9ms/step - loss: 45.1029 - val_loss: 33.1043\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 30.4403 - val_loss: 29.8691\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 800.1752 - val_loss: 176.9189\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 41.1825 - val_loss: 29.8575\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 27.1729 - val_loss: 27.4048\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "Fine-Tuning Training RMSE for individual 4: 5.2350\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 2s 8ms/step - loss: 105.5445 - val_loss: 32.5969\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 32.2824 - val_loss: 26.7021\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 27.6632 - val_loss: 31.4016\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 27.9532 - val_loss: 31.5057\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 28.4135 - val_loss: 28.1903\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "Fine-Tuning Training RMSE for individual 5: 5.3095\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 2s 9ms/step - loss: 49.5357 - val_loss: 31.8173\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 30.7840 - val_loss: 31.8592\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 28.9379 - val_loss: 29.0651\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 30.1086 - val_loss: 28.5653\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 30.3206 - val_loss: 38.0262\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "Fine-Tuning Training RMSE for individual 6: 6.1665\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 2s 9ms/step - loss: 125.1381 - val_loss: 26.0775\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 27.0002 - val_loss: 25.9046\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 27.4289 - val_loss: 25.5134\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 27.1263 - val_loss: 25.9829\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 27.3593 - val_loss: 26.3966\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "Fine-Tuning Training RMSE for individual 7: 5.1378\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 2s 8ms/step - loss: 44.0203 - val_loss: 30.5644\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 109.2289 - val_loss: 30.4814\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 32.9697 - val_loss: 30.8524\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 35.5758 - val_loss: 58.3832\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 31.3041 - val_loss: 29.9456\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "Fine-Tuning Training RMSE for individual 8: 5.4723\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 2s 8ms/step - loss: 3053.2053 - val_loss: 1782.1345\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2705.3601 - val_loss: 5752.3867\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 424.7075 - val_loss: 44.2797\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 43.8188 - val_loss: 41.5103\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 39.3052 - val_loss: 38.8275\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "Fine-Tuning Training RMSE for individual 9: 6.2312\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 2s 9ms/step - loss: 38.4192 - val_loss: 31.5003\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 29.2319 - val_loss: 30.0048\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 29.9609 - val_loss: 31.4788\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 28.8180 - val_loss: 28.8887\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 29.4256 - val_loss: 29.9325\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "Fine-Tuning Training RMSE for individual 10: 5.4711\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 2s 10ms/step - loss: 167.3160 - val_loss: 40.0333\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 30.7712 - val_loss: 28.6225\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 29.5012 - val_loss: 27.7868\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 29.7088 - val_loss: 29.4092\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 29.2160 - val_loss: 30.9989\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "Fine-Tuning Training RMSE for individual 11: 5.5677\n"
     ]
    }
   ],
   "source": [
    "# Fine-Tuning Training\n",
    "models_finetuned = {}\n",
    "for person_id in np.unique(individuals):\n",
    "    X_person = X_gl[individuals == person_id]\n",
    "    y_person = y_gl[individuals == person_id]\n",
    "    X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X_person, y_person, test_size=0.2, random_state=42,shuffle=False)\n",
    "    model_finetuned = tf.keras.models.clone_model(model_pop)  # Clone do modelo populacional\n",
    "    model_finetuned.set_weights(model_pop.get_weights())  # Inicializa com pesos treinados na população\n",
    "    model_finetuned.compile(optimizer='adam', loss='mse')\n",
    "    model_finetuned.fit(X_train_p, y_train_p, epochs=5, batch_size=8, validation_data=(X_test_p, y_test_p))  # Treino rápido\n",
    "    y_pred_ft = model_finetuned.predict(X_test_p)\n",
    "    rmse_ft = np.sqrt(mean_squared_error(y_test_p, y_pred_ft))\n",
    "    print(f'Fine-Tuning Training RMSE for individual {person_id}: {rmse_ft:.4f}')\n",
    "    models_finetuned[person_id] = model_finetuned\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kerasenv",
   "language": "python",
   "name": "kerasenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
